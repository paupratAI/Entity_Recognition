Per a experimentar amb diferents codificacions (IO, BIO, BIOW...), fer servir precision recall

Hyperparam --> BIO

Per avaluar model --> Avaluació amb entitats (p,ex 0.5*Entitats_reconegudes_parcialment/entitats_esperades)


No s'ha de cridar al postagger per cada posicio de una frase (es a dir, per cada paraula)

S'ha de precalcular els postags, o definir una classe cash en que guardem els resultats anterior --> si la frase es la mateixa,
 utlitzem el tagger que ja tenim calculat, si no, calculem el tag per la frase en questio

O bé, en comptes de tenir [('token1', 'label1'), ('token2', 'label2')], tenir en la primera posició de 'token1' --> ('token1', 'POS1')



Per la part opcional: concloure que aquesta codificacio no es la correcta per aquesta tasca


No vol l'avaluació en termes de BIO. Només s'utilitza per optimitzar hiperparam
(index_inicial-index_final, classe)
Convertir aquestes tuples a sets

Calcular Precision Recall d'entitats senceres --> comparar sets (interseccions i diferencies)

MILLOR OPCIÓ: Representar entitats com a (index_inicial, index_final, etiqueta)


Hauriem de tenir una F1 de 0.65 amb les features per defecte. I arribar a una 0.75 aprox amb la funcio millorada

Veure quin es l'efecte de cada una de les features functions de la funcio get_features.
L'objectiu no ha de ser simplement millorar aquesta funcio al maxim

Afegir capitalitzacio, prefixos, sufixos... a partir dels tokens com a baseline